{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nBayesian Models of Annotation\n=============================\n\nIn this example, we run MCMC for various crowdsourced annotation models in [1].\n\nAll models have discrete latent variables. Under the hood, we enumerate over\n(marginalize out) those discrete latent sites in inference. Those models have different\ncomplexity so they are great refererences for those who are new to Pyro/NumPyro\nenumeration mechanism. We recommend readers compare the implementations with the\ncorresponding plate diagrams in [1] to see how concise a Pyro/NumPyro program is.\n\nThe interested readers can also refer to [3] for more explanation about enumeration.\n\nThe data is taken from Table 1 of reference [2].\n\nCurrently, this example does not include postprocessing steps to deal with \"Label\nSwitching\" issue (mentioned in section 6.2 of [1]).\n\n**References:**\n\n    1. Paun, S., Carpenter, B., Chamberlain, J., Hovy, D., Kruschwitz, U.,\n       and Poesio, M. (2018). \"Comparing bayesian models of annotation\"\n       (https://www.aclweb.org/anthology/Q18-1040/)\n    2. Dawid, A. P., and Skene, A. M. (1979).\n       \"Maximum likelihood estimation of observer error\u2010rates using the EM algorithm\"\n    3. \"Inference with Discrete Latent Variables\"\n       (http://pyro.ai/examples/enumeration.html)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import argparse\nimport os\n\nfrom jax import nn, random\nimport jax.numpy as jnp\n\nimport numpyro\nfrom numpyro import handlers\nfrom numpyro.contrib.indexing import Vindex\nimport numpyro.distributions as dist\nfrom numpyro.infer import MCMC, NUTS\nfrom numpyro.infer.reparam import LocScaleReparam\n\n\ndef get_data():\n    \"\"\"\n    :return: a tuple of annotator indices and class indices. The first term has shape\n        `num_positions` whose entries take values from `0` to `num_annotators - 1`.\n        The second term has shape `num_items x num_positions` whose entries take values\n        from `0` to `num_classes - 1`.\n    \"\"\"\n    # NB: the first annotator assessed each item 3 times\n    positions = jnp.array([1, 1, 1, 2, 3, 4, 5])\n    annotations = jnp.array([\n        [1, 3, 1, 2, 2, 2, 1, 3, 2, 2, 4, 2, 1, 2, 1,\n         1, 1, 1, 2, 2, 2, 2, 2, 2, 1, 1, 2, 1, 1, 1,\n         1, 3, 1, 2, 2, 4, 2, 2, 3, 1, 1, 1, 2, 1, 2],\n        [1, 3, 1, 2, 2, 2, 2, 3, 2, 3, 4, 2, 1, 2, 2,\n         1, 1, 1, 2, 2, 2, 2, 2, 2, 1, 1, 3, 1, 1, 1,\n         1, 3, 1, 2, 2, 3, 2, 3, 3, 1, 1, 2, 3, 2, 2],\n        [1, 3, 2, 2, 2, 2, 2, 3, 2, 2, 4, 2, 1, 2, 1,\n         1, 1, 1, 2, 2, 2, 2, 2, 1, 1, 1, 2, 1, 1, 2,\n         1, 3, 1, 2, 2, 3, 1, 2, 3, 1, 1, 1, 2, 1, 2],\n        [1, 4, 2, 3, 3, 3, 2, 3, 2, 2, 4, 3, 1, 3, 1,\n         2, 1, 1, 2, 1, 2, 2, 3, 2, 1, 1, 2, 1, 1, 1,\n         1, 3, 1, 2, 3, 4, 2, 3, 3, 1, 1, 2, 2, 1, 2],\n        [1, 3, 1, 1, 2, 3, 1, 4, 2, 2, 4, 3, 1, 2, 1,\n         1, 1, 1, 2, 3, 2, 2, 2, 2, 1, 1, 2, 1, 1, 1,\n         1, 2, 1, 2, 2, 3, 2, 2, 4, 1, 1, 1, 2, 1, 2],\n        [1, 3, 2, 2, 2, 2, 1, 3, 2, 2, 4, 4, 1, 1, 1,\n         1, 1, 1, 2, 2, 2, 2, 2, 2, 1, 1, 2, 1, 1, 2,\n         1, 3, 1, 2, 3, 4, 3, 3, 3, 1, 1, 1, 2, 1, 2],\n        [1, 4, 2, 1, 2, 2, 1, 3, 3, 3, 4, 3, 1, 2, 1,\n         1, 1, 1, 1, 2, 2, 1, 2, 2, 1, 1, 2, 1, 1, 1,\n         1, 3, 1, 2, 2, 3, 2, 3, 2, 1, 1, 1, 2, 1, 2],\n    ]).T\n    # we minus 1 because in Python, the first index is 0\n    return positions - 1, annotations - 1\n\n\ndef multinomial(annotations):\n    \"\"\"\n    This model corresponds to the plate diagram in Figure 1 of reference [1].\n    \"\"\"\n    num_classes = int(jnp.max(annotations)) + 1\n    num_items, num_positions = annotations.shape\n\n    with numpyro.plate(\"class\", num_classes):\n        zeta = numpyro.sample(\"zeta\", dist.Dirichlet(jnp.ones(num_classes)))\n\n    pi = numpyro.sample(\"pi\", dist.Dirichlet(jnp.ones(num_classes)))\n\n    with numpyro.plate(\"item\", num_items, dim=-2):\n        c = numpyro.sample(\"c\", dist.Categorical(pi))\n\n        with numpyro.plate(\"position\", num_positions):\n            numpyro.sample(\"y\", dist.Categorical(zeta[c]), obs=annotations)\n\n\ndef dawid_skene(positions, annotations):\n    \"\"\"\n    This model corresponds to the plate diagram in Figure 2 of reference [1].\n    \"\"\"\n    num_annotators = int(jnp.max(positions)) + 1\n    num_classes = int(jnp.max(annotations)) + 1\n    num_items, num_positions = annotations.shape\n\n    with numpyro.plate(\"annotator\", num_annotators, dim=-2):\n        with numpyro.plate(\"class\", num_classes):\n            beta = numpyro.sample(\"beta\", dist.Dirichlet(jnp.ones(num_classes)))\n\n    pi = numpyro.sample(\"pi\", dist.Dirichlet(jnp.ones(num_classes)))\n\n    with numpyro.plate(\"item\", num_items, dim=-2):\n        c = numpyro.sample(\"c\", dist.Categorical(pi))\n\n        # here we use Vindex to allow broadcasting for the second index `c`\n        # ref: http://num.pyro.ai/en/latest/utilities.html#numpyro.contrib.indexing.vindex\n        with numpyro.plate(\"position\", num_positions):\n            numpyro.sample(\"y\", dist.Categorical(Vindex(beta)[positions, c, :]), obs=annotations)\n\n\ndef mace(positions, annotations):\n    \"\"\"\n    This model corresponds to the plate diagram in Figure 3 of reference [1].\n    \"\"\"\n    num_annotators = int(jnp.max(positions)) + 1\n    num_classes = int(jnp.max(annotations)) + 1\n    num_items, num_positions = annotations.shape\n\n    with numpyro.plate(\"annotator\", num_annotators):\n        epsilon = numpyro.sample(\"epsilon\", dist.Dirichlet(jnp.full(num_classes, 10)))\n        theta = numpyro.sample(\"theta\", dist.Beta(0.5, 0.5))\n\n    with numpyro.plate(\"item\", num_items, dim=-2):\n        # NB: using constant logits for discrete uniform prior\n        # (NumPyro does not have DiscreteUniform distribution yet)\n        c = numpyro.sample(\"c\", dist.Categorical(logits=jnp.zeros(num_classes)))\n\n        with numpyro.plate(\"position\", num_positions):\n            s = numpyro.sample(\"s\", dist.Bernoulli(1 - theta[positions]))\n            probs = jnp.where(s[..., None] == 0, nn.one_hot(c, num_classes), epsilon[positions])\n            numpyro.sample(\"y\", dist.Categorical(probs), obs=annotations)\n\n\ndef hierarchical_dawid_skene(positions, annotations):\n    \"\"\"\n    This model corresponds to the plate diagram in Figure 4 of reference [1].\n    \"\"\"\n    num_annotators = int(jnp.max(positions)) + 1\n    num_classes = int(jnp.max(annotations)) + 1\n    num_items, num_positions = annotations.shape\n\n    with numpyro.plate(\"class\", num_classes):\n        # NB: we define `beta` as the `logits` of `y` likelihood; but `logits` is\n        # invariant up to a constant, so we'll follow [1]: fix the last term of `beta`\n        # to 0 and only define hyperpriors for the first `num_classes - 1` terms.\n        zeta = numpyro.sample(\"zeta\", dist.Normal(0, 1).expand([num_classes - 1]).to_event(1))\n        omega = numpyro.sample(\"Omega\", dist.HalfNormal(1).expand([num_classes - 1]).to_event(1))\n\n    with numpyro.plate(\"annotator\", num_annotators, dim=-2):\n        with numpyro.plate(\"class\", num_classes):\n            # non-centered parameterization\n            with handlers.reparam(config={\"beta\": LocScaleReparam(0)}):\n                beta = numpyro.sample(\"beta\", dist.Normal(zeta, omega).to_event(1))\n            # pad 0 to the last item\n            beta = jnp.pad(beta, [(0, 0)] * (jnp.ndim(beta) - 1) + [(0, 1)])\n\n    pi = numpyro.sample(\"pi\", dist.Dirichlet(jnp.ones(num_classes)))\n\n    with numpyro.plate(\"item\", num_items, dim=-2):\n        c = numpyro.sample(\"c\", dist.Categorical(pi))\n\n        with numpyro.plate(\"position\", num_positions):\n            logits = Vindex(beta)[positions, c, :]\n            numpyro.sample(\"y\", dist.Categorical(logits=logits), obs=annotations)\n\n\ndef item_difficulty(annotations):\n    \"\"\"\n    This model corresponds to the plate diagram in Figure 5 of reference [1].\n    \"\"\"\n    num_classes = int(jnp.max(annotations)) + 1\n    num_items, num_positions = annotations.shape\n\n    with numpyro.plate(\"class\", num_classes):\n        eta = numpyro.sample(\"eta\", dist.Normal(0, 1).expand([num_classes - 1]).to_event(1))\n        chi = numpyro.sample(\"Chi\", dist.HalfNormal(1).expand([num_classes - 1]).to_event(1))\n\n    pi = numpyro.sample(\"pi\", dist.Dirichlet(jnp.ones(num_classes)))\n\n    with numpyro.plate(\"item\", num_items, dim=-2):\n        c = numpyro.sample(\"c\", dist.Categorical(pi))\n\n        with handlers.reparam(config={\"theta\": LocScaleReparam(0)}):\n            theta = numpyro.sample(\"theta\", dist.Normal(eta[c], chi[c]).to_event(1))\n            theta = jnp.pad(theta, [(0, 0)] * (jnp.ndim(theta) - 1) + [(0, 1)])\n\n        with numpyro.plate(\"position\", annotations.shape[-1]):\n            numpyro.sample(\"y\", dist.Categorical(logits=theta), obs=annotations)\n\n\ndef logistic_random_effects(positions, annotations):\n    \"\"\"\n    This model corresponds to the plate diagram in Figure 5 of reference [1].\n    \"\"\"\n    num_annotators = int(jnp.max(positions)) + 1\n    num_classes = int(jnp.max(annotations)) + 1\n    num_items, num_positions = annotations.shape\n\n    with numpyro.plate(\"class\", num_classes):\n        zeta = numpyro.sample(\"zeta\", dist.Normal(0, 1).expand([num_classes - 1]).to_event(1))\n        omega = numpyro.sample(\"Omega\", dist.HalfNormal(1).expand([num_classes - 1]).to_event(1))\n        chi = numpyro.sample(\"Chi\", dist.HalfNormal(1).expand([num_classes - 1]).to_event(1))\n\n    with numpyro.plate(\"annotator\", num_annotators, dim=-2):\n        with numpyro.plate(\"class\", num_classes):\n            with handlers.reparam(config={\"beta\": LocScaleReparam(0)}):\n                beta = numpyro.sample(\"beta\", dist.Normal(zeta, omega).to_event(1))\n                beta = jnp.pad(beta, [(0, 0)] * (jnp.ndim(beta) - 1) + [(0, 1)])\n\n    pi = numpyro.sample(\"pi\", dist.Dirichlet(jnp.ones(num_classes)))\n\n    with numpyro.plate(\"item\", num_items, dim=-2):\n        c = numpyro.sample(\"c\", dist.Categorical(pi))\n\n        with handlers.reparam(config={\"theta\": LocScaleReparam(0)}):\n            theta = numpyro.sample(\"theta\", dist.Normal(0, chi[c]).to_event(1))\n            theta = jnp.pad(theta, [(0, 0)] * (jnp.ndim(theta) - 1) + [(0, 1)])\n\n        with numpyro.plate(\"position\", num_positions):\n            logits = Vindex(beta)[positions, c, :] - theta\n            numpyro.sample(\"y\", dist.Categorical(logits=logits), obs=annotations)\n\n\nNAME_TO_MODEL = {\n    \"mn\": multinomial,\n    \"ds\": dawid_skene,\n    \"mace\": mace,\n    \"hds\": hierarchical_dawid_skene,\n    \"id\": item_difficulty,\n    \"lre\": logistic_random_effects,\n}\n\n\ndef main(args):\n    annotators, annotations = get_data()\n    model = NAME_TO_MODEL[args.model]\n    data = (annotations,) if model in [multinomial, item_difficulty] else (annotators, annotations)\n\n    mcmc = MCMC(\n        NUTS(model),\n        args.num_warmup,\n        args.num_samples,\n        num_chains=args.num_chains,\n        progress_bar=False if \"NUMPYRO_SPHINXBUILD\" in os.environ else True,\n    )\n    mcmc.run(random.PRNGKey(0), *data)\n    mcmc.print_summary()\n\n\nif __name__ == \"__main__\":\n    assert numpyro.__version__.startswith(\"0.3.0\")\n    parser = argparse.ArgumentParser(description=\"Bayesian Models of Annotation\")\n    parser.add_argument(\"-n\", \"--num-samples\", nargs=\"?\", default=1000, type=int)\n    parser.add_argument(\"--num-warmup\", nargs=\"?\", default=1000, type=int)\n    parser.add_argument(\"--num-chains\", nargs=\"?\", default=1, type=int)\n    parser.add_argument(\n        \"--model\",\n        nargs=\"?\",\n        default=\"ds\",\n        help='one of \"mn\" (multinomial), \"ds\" (dawid_skene), \"mace\",'\n        ' \"hds\" (hierarchical_dawid_skene),'\n        ' \"id\" (item_difficulty), \"lre\" (logistic_random_effects)',\n    )\n    parser.add_argument(\"--device\", default=\"cpu\", type=str, help='use \"cpu\" or \"gpu\".')\n    args = parser.parse_args()\n\n    numpyro.set_platform(args.device)\n    numpyro.set_host_device_count(args.num_chains)\n\n    main(args)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}